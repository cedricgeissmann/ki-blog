<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>KI Blog</title>

  <link rel="stylesheet" href="blog.css">
</head>
<body>
  <nav>
    <ul>
      <li><a href="Frage1.html">Über KI</a></li></li>
      <li><a href="Frage2.html">Wie funktioniert KI</a></li></li>
      <li><a href="Frage3.html">Neuronales Netzwerk</a></li></li>
      <li><a href="Frage4.html">Maschinelles Lernen</a></li></li>
      <li><a href="Frage5.html">Einfluss von Daten</a></li></li>
      <li><a href="Frage6.html">Wie funktioniert Chat-GPT </a></li></li>
      <li><a href="Frage7.html">Grenzen und Verwedung</a></li></li>
    </ul>
  </nav>
  <main>
    <h1>Neuronales Netzwerk</h1>
    <section>

     <p></p>
     Eingabeschicht: Die Eingabeschicht ist die erste Schicht im neuronalen Netzwerk. Sie nimmt die Eingabedaten auf, die als Merkmalsvektoren codiert werden. Zum Beispiel können dies Pixelwerte von Bildern oder numerische Werte von Sensordaten sein.
     <p></p>
     Verborgene Schichten: Nach der Eingabeschicht können eine oder mehrere verborgene Schichten folgen. Jede Schicht besteht aus einer bestimmten Anzahl von Neuronen. Die verborgenen Schichten dienen dazu, komplexe Merkmale und Abhängigkeiten in den Eingabedaten zu erfassen und zu lernen.
     Gewichtungen und Aktivierungsfunktionen: Jede Verbindung zwischen den Neuronen im Netzwerk hat eine Gewichtung, die anzeigt, wie stark oder schwach die Verbindung ist. Wenn ein Neuron in einer Schicht aktiviert wird, multipliziert es seine Eingabe mit den entsprechenden Gewichtungen und summiert sie auf. Anschließend wird eine Aktivierungsfunktion auf die gewichtete Summe angewendet, um die Ausgabe des Neurons zu berechnen. Häufig verwendete Aktivierungsfunktionen sind die Sigmoidfunktion, die ReLU-Funktion (Rectified Linear Unit) oder die tanh-Funktion (Hyperbolic Tangent).
     <p></p>
     Ausgabeschicht: Die Ausgabeschicht ist die letzte Schicht des Netzwerks. Sie erzeugt die Ausgabe des neuronalen Netzwerks basierend auf den berechneten Aktivierungen der vorherigen Schichten. Die Anzahl der Neuronen in der Ausgabeschicht hängt von der Art des Problems ab, das das Netzwerk lösen soll. Bei einem Klassifizierungsproblem kann jedes Neuron zum Beispiel für eine bestimmte Klasse stehen und seine Aktivierung die Wahrscheinlichkeit repräsentieren, dass die Eingabe zu dieser Klasse gehört.
     <p></p>
     Lernen und Anpassung: Der Lernprozess im neuronalen Netzwerk besteht darin, die Gewichtungen zwischen den Neuronen so anzupassen, dass das Netzwerk die gewünschte Ausgabe für eine gegebene Eingabe erzeugt. Dies geschieht durch sogenanntes "Backpropagation", bei dem der Fehler zwischen den tatsächlichen Ausgaben des Netzwerks und den erwarteten Ausgaben berechnet und dann rückwärts durch das Netzwerk propagiert wird, um die Gewichtungen anzupassen. Dieser Prozess wird normalerweise mit Hilfe von Optimierungsalgorithmen wie dem Gradientenabstiegsverfahren durchgeführt.
     Durch wiederholtes Anpassen der Gewichtungen während des Lernprozesses kann das neuronale Netzwerk lernen, Muster und Zusammenhänge in den Trainingsdaten zu erkennen und diese auf neue Daten anzuwenden, um Vorhersagen oder Entscheidungen zu treffen.
     
     Es ist wichtig anzumerken, dass dies eine vereinfachte Erklärung ist und es viele Varianten und Erweiterungen von neuronalen Netzwerken gibt, wie z.B. Convolutional Neural Networks (CNNs) für die Bildverarbeitung oder Recurrent Neural Networks (RNNs) für die Verarbeitung von Sequenzen.
     
     
     
     
     
     
    </section>
  </main>
</body>
</html>